---
title: "SOC-5811 Week 6: Simulation"
author: "Nick Graetz"
date: "10/6/2025"
output: 
    beamer_presentation:
        incremental: false
        includes: 
            in_header: Minnesota.tex
---

```{r setup, include=FALSE}
## Libraries
library(tidyverse)
library(data.table)
library(ggplot2)
library(haven)
library(formatR)
library(marginaleffects)
library(cowplot)
# knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 20), tidy = TRUE)
knitr::opts_chunk$set(
 fig.width = 6,
 fig.height = 4,
 warning = FALSE, 
 message = FALSE
)
dropbox <- 'C:/Users/ngraetz/Dropbox/'
fig_dir <- paste0(dropbox,
                  'Minnesota/repos/soc5811/figures/')
data_dir <- paste0(dropbox,
                   'Minnesota/repos/soc5811/data/')
```

---

\frametitle{Review}

>- Sampling distributions

>- Inference

>- p-values

---

\frametitle{Simulation}

Why is simulation an important concept/skill? 

>- Develop statistical intuition without needing math

>- Very important with more complex models: you can always simulate

>- Summarizing our models 

>- Bootstrapping

---

\frametitle{Simulation}

* Simulating a sampling distribution when you \textbf{know} the underlying probability model.

```{r, echo=TRUE}
get_sample_size <- function(size) {
  get_sample <- function(i,size) {
    test <- data.table(income=round(rnorm(size, 65, 20))) ## Known mean/SE
    return(mean(test[,income]))
  }
  test <- unlist(lapply(1:1000, get_sample, size=size))
  test <- data.table(income=test)
  test[, size := size]
  return(test)
}
test <- rbindlist(lapply(c(30,100,400), get_sample_size))
ggplot(data=test,
         aes(x=income)) + 
    geom_histogram(color=NA,fill='grey') + 
    facet_wrap(~size,nrow=1) + 
    labs(x='Income',y='Count') + 
    theme_bw()
```

---

\frametitle{Simulation}

* Simulating a sampling distribution when you \textbf{do not know} the underlying probability model.

* Randomly sample the \textbf{observed} data and calculate your statistic many times ("bootstrapping").

---

\frametitle{Bootstrap}

\small
```{r, echo=TRUE}
census <- read_dta(paste0(data_dir,
                          'state_pophouse.dta'))
get_sample <- function(i) {
  random_sample <- census %>%
    sample_n(size=51,replace=T) %>%
    summarise(mean=mean(pcthouse))
  return(random_sample)
}
samples <- rbindlist(lapply(1:1000,get_sample))
se_bootstrap <- sd(samples$mean)
se_analytic <- sd(census$pcthouse)/sqrt(nrow(census))
```

---

\frametitle{Sampling distributions}

* Review mean and standard deviation (SD)
* What is a standard error? How does it relate to the SD?
* Use sampling to show that SE is standard deviation of the sampling distribution
* SE from regression results = SD of the sampling distribution we made
* We call this "bootstrapping" the SE

\tiny
```{r, echo=TRUE}
get_sample <- function(i) {
  message(i)
  random_sample <- sample_n(census,size=51,replace=T)
  model <- lm(pcthouse~pctpop,
            data=random_sample)
  out <- avg_slopes(model)
  return(out)
}
coef_samples <- rbindlist(lapply(1:100, get_sample))
sd(coef_samples$estimate)

## Compare to lm()
model <- lm(pcthouse~pctpop, data=census)
```

---
